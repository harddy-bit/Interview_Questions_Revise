from pyspark.sql import SparkSession

# Initialize Spark Session
spark = SparkSession.builder.appName("Flatten JSON").getOrCreate()
# Sample JSON data
data = [
    {
        "customer_id": 1,
        "name": "Parth",
        "orders": [
            {"order_id": 101, "product": "Laptop", "quantity": 2},
            {"order_id": 102, "product": "Phone", "quantity": 1}
        ]
    },
    {
        "customer_id": 2,
        "name": "Rajesh",
        "orders": [
            {"order_id": 103, "product": "Tablet", "quantity": 3},
            {"order_id": 104, "product": "Headphones", "quantity": 2}
        ]
    }
]
# Create DataFrame
df = spark.read.json(spark.sparkContext.parallelize([data]))
df.show(truncate=False)


# # Sample Ouput:
# customer_id	name	order_id	product  	quantitiy
# 1	        Parth	  101	        Laptop	              2
# 1	        Parth	  102	        Phone	              1
# 2	        Rajesh	  103	        Tablet	              3
# 2	        Rajesh	  104	       Headphones	      2

--------------------------------------------------------------------------------

## Step 1: Flatten the nested structure (explode orders)
flat_df = df.withColumn("order", explode(col("orders")))

flat_df.show(truncate=False)

## Step 2: Select the required columns
flat_df = flat_df.select(
    "customer_id",
    "name",
    col("order.order_id").alias("order_id"),
    col("order.product").alias("product"),
    col("order.quantity").alias("quantity")
)

print("Flattened Data:")

flat_df.show(truncate=False)
